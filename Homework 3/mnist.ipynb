{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Домашнее задание №7\n\n##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nimport torchvision\nfrom torchvision.datasets import MNIST\nimport torchvision.transforms as T\nfrom matplotlib import pyplot as plt\nfrom IPython.display import clear_output","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:38:52.759470Z","iopub.execute_input":"2023-11-18T09:38:52.760321Z","iopub.status.idle":"2023-11-18T09:38:52.765551Z","shell.execute_reply.started":"2023-11-18T09:38:52.760284Z","shell.execute_reply":"2023-11-18T09:38:52.764525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задача №1: \nОбратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В данном задании воспользуемся всем датасетом целиком.\n\n__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n\nКод для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку первого занятия.\n\nНастоятельно рекомендуем написать код \"с нуля\", лишь поглядывая на готовые примеры, а не просто \"скопировать-вставить\". Это поможет вам в дальнейшем.","metadata":{}},{"cell_type":"code","source":"augs = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n                                       T.RandomRotation(degrees=10),\n                                       ])","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:48:43.400566Z","iopub.execute_input":"2023-11-18T09:48:43.401211Z","iopub.status.idle":"2023-11-18T09:48:43.406008Z","shell.execute_reply.started":"2023-11-18T09:48:43.401179Z","shell.execute_reply":"2023-11-18T09:48:43.405102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# do not change the code in the block below\n# __________start of block__________\n\ntrain_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\ntest_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n\n\ntrain_data_loader = torch.utils.data.DataLoader(\n    train_mnist_data,\n    batch_size=32,\n    shuffle=True,\n    num_workers=2\n)\n\ntest_data_loader = torch.utils.data.DataLoader(\n    test_mnist_data,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2\n)\n\nrandom_batch = next(iter(train_data_loader))\n_image, _label = random_batch[0][0], random_batch[1][0]\nplt.figure()\nplt.imshow(_image.reshape(28, 28))\nplt.title(f'Image label: {_label}')\n# __________end of block__________","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:52:13.059680Z","iopub.execute_input":"2023-11-18T09:52:13.060054Z","iopub.status.idle":"2023-11-18T09:52:13.567565Z","shell.execute_reply.started":"2023-11-18T09:52:13.060024Z","shell.execute_reply":"2023-11-18T09:52:13.566494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 92% accuracy.\n\n*Комментарий: для этого достаточно линейных слоев и функций активации.*\n\n__Внимание, ваша модель должна быть представлена именно переменной `model`.__","metadata":{}},{"cell_type":"code","source":"train_mnist_data[0][0]","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:43:31.959363Z","iopub.execute_input":"2023-11-18T09:43:31.960216Z","iopub.status.idle":"2023-11-18T09:43:31.967863Z","shell.execute_reply.started":"2023-11-18T09:43:31.960183Z","shell.execute_reply":"2023-11-18T09:43:31.966831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating model instance\nmodel = nn.Sequential(nn.Flatten(),\n                      nn.Linear(in_features=28 * 28, out_features=2048),\n                      nn.GELU(),\n                      nn.Linear(in_features=2048, out_features=4096),\n                      nn.GELU(),\n                      nn.Linear(in_features=4096, out_features=512),\n                      nn.GELU(),\n                      nn.Linear(in_features=512, out_features=10),\n                      #nn.ReLU(),\n                      #nn.Softmax(dim=1)\n                      )\nmodel = model.to(device) # your code here","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:54:09.851060Z","iopub.execute_input":"2023-11-18T09:54:09.851454Z","iopub.status.idle":"2023-11-18T09:54:09.965349Z","shell.execute_reply.started":"2023-11-18T09:54:09.851420Z","shell.execute_reply":"2023-11-18T09:54:09.964544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\nclear_output()\nfrom torchsummary import summary\nsummary(model, (1, 28, 28))","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:54:10.489195Z","iopub.execute_input":"2023-11-18T09:54:10.489580Z","iopub.status.idle":"2023-11-18T09:54:10.519887Z","shell.execute_reply.started":"2023-11-18T09:54:10.489548Z","shell.execute_reply":"2023-11-18T09:54:10.518667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=5, gamma=0.5)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:54:11.119350Z","iopub.execute_input":"2023-11-18T09:54:11.119763Z","iopub.status.idle":"2023-11-18T09:54:11.126328Z","shell.execute_reply.started":"2023-11-18T09:54:11.119728Z","shell.execute_reply":"2023-11-18T09:54:11.125212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(\n    model: nn.Module,\n    data_loader,\n    optimizer,\n    loss_fn,\n    device: torch.device,\n) -> tuple[float, float]:\n    model.train()\n\n    total_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(data_loader, desc=\"Train\"):\n        x, y = x.to(device), y.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(x)\n\n        loss = loss_fn(output, y)\n\n        loss.backward()\n\n        total_loss += loss.item()\n\n        optimizer.step()\n\n        _, y_pred = torch.max(output, 1)\n        total += y.size(0)\n        correct += (y_pred == y).sum().item()\n\n    return total_loss / len(data_loader), correct / total\n\n\n@torch.inference_mode()\ndef evaluate(\n    model: nn.Module, data_loader, loss_fn, device: torch.device\n) -> tuple[float, float]:\n    model.eval()\n\n    total_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(data_loader, desc=\"Evaluate\"):\n        x, y = x.to(device), y.to(device)\n\n        output = model(x)\n\n        loss = loss_fn(output, y)\n\n        total_loss += loss.item()\n\n        _, y_pred = torch.max(output, 1)\n        total += y.size(0)\n        correct += (y_pred == y).sum().item()\n\n    return total_loss / len(data_loader), correct / total\n\n\ndef plot_stats(\n    train_loss: list[float],\n    valid_loss: list[float],\n    train_accuracy: list[float],\n    valid_accuracy: list[float],\n    title: str,\n):\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + \" loss\")\n\n    plt.plot(train_loss, label=\"Train loss\")\n    plt.plot(valid_loss, label=\"Valid loss\")\n    plt.legend()\n    plt.grid()\n\n    plt.show()\n\n    plt.figure(figsize=(16, 8))\n\n    plt.title(title + \" accuracy\")\n\n    plt.plot(train_accuracy, label=\"Train accuracy\")\n    plt.plot(valid_accuracy, label=\"Valid accuracy\")\n    plt.legend()\n    plt.grid()\n\n    plt.show()\n\n\ndef whole_train_valid_cycle(\n    model, train_loader, valid_loader, optimizer, loss_fn, device, threshold, title\n):\n    train_loss_history, valid_loss_history = [], []\n    train_accuracy_history, valid_accuracy_history = [], []\n\n    for epoch in range(100):\n        train_loss, train_accuracy = train(\n            model, train_data_loader, optimizer, loss_fn, device\n        )\n        valid_loss, valid_accuracy = evaluate(model, test_data_loader, loss_fn, device)\n        \n        scheduler.step()\n        \n        train_loss_history.append(train_loss)\n        valid_loss_history.append(valid_loss)\n\n        train_accuracy_history.append(train_accuracy)\n        valid_accuracy_history.append(valid_accuracy)\n\n        clear_output(wait=True)\n\n        plot_stats(\n            train_loss_history,\n            valid_loss_history,\n            train_accuracy_history,\n            valid_accuracy_history,\n            title,\n        )\n\n        if valid_accuracy >= threshold:\n            break\n    \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:54:12.052073Z","iopub.execute_input":"2023-11-18T09:54:12.052741Z","iopub.status.idle":"2023-11-18T09:54:12.070680Z","shell.execute_reply.started":"2023-11-18T09:54:12.052704Z","shell.execute_reply":"2023-11-18T09:54:12.069664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole_train_valid_cycle(model, train_loader=train_data_loader, optimizer=optimizer, threshold=1, valid_loader=test_data_loader, loss_fn=loss_fn, device=device, title='mnist')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:58:38.488798Z","iopub.execute_input":"2023-11-18T09:58:38.489257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Локальные тесты для проверки вашей модели доступны ниже:","metadata":{}},{"cell_type":"code","source":"# do not change the code in the block below\n# __________start of block__________\nassert model is not None, 'Please, use `model` variable to store your model'\n\ntry:\n    x = random_batch[0].reshape(-1, 784).to(device)\n    y = random_batch[1].to(device)\n\n    # compute outputs given inputs, both are variables\n    y_predicted = model(x).to(device)    \nexcept Exception as e:\n    print('Something is wrong with the model')\n    raise e\n    \n    \nassert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n\nprint('Everything seems fine!')\n# __________end of block__________","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:54:50.837775Z","iopub.execute_input":"2023-11-18T09:54:50.838145Z","iopub.status.idle":"2023-11-18T09:54:50.847011Z","shell.execute_reply.started":"2023-11-18T09:54:50.838119Z","shell.execute_reply":"2023-11-18T09:54:50.846005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  ","metadata":{}},{"cell_type":"markdown","source":"Оценим качество классификации:","metadata":{}},{"cell_type":"code","source":"predicted_labels = []\nreal_labels = []\nmodel.eval()\nwith torch.no_grad():\n    for batch in train_data_loader:\n        y_predicted = model(batch[0].reshape(-1, 784).to(device))\n        predicted_labels.append(y_predicted.argmax(dim=1))\n        real_labels.append(batch[1])\n\npredicted_labels = torch.cat(predicted_labels).to(device)\nreal_labels = torch.cat(real_labels).to(device)\ntrain_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:54:52.231032Z","iopub.execute_input":"2023-11-18T09:54:52.231760Z","iopub.status.idle":"2023-11-18T09:54:59.359679Z","shell.execute_reply.started":"2023-11-18T09:54:52.231725Z","shell.execute_reply":"2023-11-18T09:54:59.357938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Neural network accuracy on train set: {train_acc:3.5}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:54:59.361399Z","iopub.execute_input":"2023-11-18T09:54:59.362077Z","iopub.status.idle":"2023-11-18T09:54:59.368466Z","shell.execute_reply.started":"2023-11-18T09:54:59.362048Z","shell.execute_reply":"2023-11-18T09:54:59.367545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = []\nreal_labels = []\nmodel.eval()\nwith torch.no_grad():\n    for batch in test_data_loader:\n        y_predicted = model(batch[0].reshape(-1, 784).to(device))\n        predicted_labels.append(y_predicted.argmax(dim=1))\n        real_labels.append(batch[1])\n\npredicted_labels = torch.cat(predicted_labels).to(device)\nreal_labels = torch.cat(real_labels).to(device)\ntest_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:55:00.701305Z","iopub.execute_input":"2023-11-18T09:55:00.702239Z","iopub.status.idle":"2023-11-18T09:55:02.013720Z","shell.execute_reply.started":"2023-11-18T09:55:00.702202Z","shell.execute_reply":"2023-11-18T09:55:02.012375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Neural network accuracy on test set: {test_acc:3.5}')","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:55:09.184928Z","iopub.execute_input":"2023-11-18T09:55:09.185320Z","iopub.status.idle":"2023-11-18T09:55:09.190944Z","shell.execute_reply.started":"2023-11-18T09:55:09.185288Z","shell.execute_reply":"2023-11-18T09:55:09.189856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Проверка, что необходимые пороги пройдены:","metadata":{}},{"cell_type":"code","source":"assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\nassert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:55:12.478609Z","iopub.execute_input":"2023-11-18T09:55:12.479044Z","iopub.status.idle":"2023-11-18T09:55:12.484441Z","shell.execute_reply.started":"2023-11-18T09:55:12.479004Z","shell.execute_reply":"2023-11-18T09:55:12.483529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сдача задания\nЗагрузите файл `hw07_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/girafe-ai/ml-course/23s_dd_ml/homeworks/hw07_mnist_classification/hw07_data_dict.npy","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:55:20.096107Z","iopub.execute_input":"2023-11-18T09:55:20.096502Z","iopub.status.idle":"2023-11-18T09:55:21.388819Z","shell.execute_reply.started":"2023-11-18T09:55:20.096458Z","shell.execute_reply":"2023-11-18T09:55:21.387326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# do not change the code in the block below\n# __________start of block__________\nimport os\n\nassert os.path.exists('hw07_data_dict.npy'), 'Please, download `hw07_data_dict.npy` and place it in the working directory'\n\ndef get_predictions(model, eval_data, step=10):\n    \n    predicted_labels = []\n    model.eval()\n    with torch.no_grad():\n        for idx in range(0, len(eval_data), step):\n            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784).to(device))\n            predicted_labels.append(y_predicted.argmax(dim=1))\n    \n    predicted_labels = torch.cat(predicted_labels).to(device)\n    return predicted_labels.cpu()\n\nloaded_data_dict = np.load('hw07_data_dict.npy', allow_pickle=True)\n\nsubmission_dict = {\n    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])).numpy(),\n    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test'])).numpy()\n}\n\nnp.save('submission_dict_hw07.npy', submission_dict, allow_pickle=True)\nprint('File saved to `submission_dict_hw07.npy`')\n# __________end of block__________","metadata":{"execution":{"iopub.status.busy":"2023-11-18T09:56:44.233544Z","iopub.execute_input":"2023-11-18T09:56:44.233952Z","iopub.status.idle":"2023-11-18T09:56:44.317220Z","shell.execute_reply.started":"2023-11-18T09:56:44.233920Z","shell.execute_reply":"2023-11-18T09:56:44.316332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"На этом задание завершено. Поздравляем!","metadata":{}}]}